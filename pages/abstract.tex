% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex

%**************************************************************
% Sommario
%**************************************************************
\cleardoublepage
\phantomsection
\pdfbookmark{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

With the advent of high-computational devices, deep neural networks have gained a lot of popularity in solving many Natural Language Processing tasks. 
However, they are also vulnerable to adversarial attacks, which are able to modify the input text in order to mislead the target model. 
Adversarial attacks are a serious threat to the security of deep neural networks, and they can be used to craft adversarial examples that steer the model towards a wrong decision.

In this dissertation, we propose SynBA, a novel contextualized synonym-based adversarial attack for text classification. 
SynBA is based on the idea of replacing words in the input text with their synonyms, which are selected according to the context of the sentence. 

We show that SynBA successfully generates adversarial examples that are able to fool the target model with a high success rate. 
We demonstrate three advantages of this proposed approach: (1) effective---it outperforms state-of-the-art attacks by semantic similarity and perturbation rate, (2) utility-preserving---it preserves semantic content, grammaticality, and correct types classified by humans, and (3) efficient---it performs attacks faster than other methods.


\endgroup

\vfill

