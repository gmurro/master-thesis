%**************************************************************
% Acronimi
%**************************************************************
\renewcommand{\acronymname}{Acronimi e abbreviazioni}
%**************************************************************

\newacronym[description={\glslink{aig}{Artificial Intelligence}}]
{ai}{AI}{Artificial Intelligence}
\newglossaryentry{aig}
{
    name=\glslink{ai}{AI},
    text= Artificial Intelligence,
    sort= ai,
    description={Artificial Intelligence is a branch of computer science that aims to machines able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.}
}


\newacronym[description={\glslink{nlpg}{Natural Language Processing}}]
{nlp}{NLP}{Natural Language Processing}
\newglossaryentry{nlpg}
{
    name=\glslink{nlp}{NLP},
    text= Natural Language Processing,
    sort= nlp,
    description={Natural Language Processing is an important field of Artificial Intelligence, linguistics and computer science. It 's about the interactions between computers and human language, in particular, how to program computers to process and analyze large amounts of natural language data.}
}

\newacronym[description={\glslink{cvg}{Computer Vision}}]
{cv}{CV}{Computer Vision}
\newglossaryentry{cvg}
{
    name=\glslink{cv}{CV},
    text=Computer Vision,
    sort= cv,
    description={Computer Vision is the field of study that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.}
}

\newacronym[description={\glslink{cnng}{Convolutional Neural Network}}]
{cnn}{CNN}{Convolutional Neural Network}
\newglossaryentry{cnng}
{
    name=\glslink{cnn}{CNN},
    text=Convolutional Neural Network,
    sort= cv,
    description={Convolutional Neural Networks are a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks, based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, and financial time series.}
}

\newacronym[description={\glslink{rnnlg}{Recurrent Neural Network}}]
{rnn}{RNN}{Recurrent Neural Network}
\newglossaryentry{rnnlg}
{
    name=\glslink{rnn}{RNN},
    text=Recurrent Neural Network,
    sort= rnn,
    description={Recurrent Neural Networks are a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.}
}

\newacronym[description={\glslink{lstmg}{Long Short-Term Memory}}]
{lstm}{LSTM}{Long Short-Term Memory}
\newglossaryentry{lstmg}
{
    name=\glslink{lstm}{LSTM},
    text=Long Short-Term Memory,
    sort= lstm,
    description={Long Short-Term Memory is a type of recurrent neural network architecture used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.}
}

\newacronym[description={\glslink{mlmg}{Masked language model}}]
{mlm}{MLM}{Masked language model}
\newglossaryentry{mlmg}
{
    name=\glslink{mlm}{MLM},
    text=Masked language model,
    sort= mlm,
    description={Masked language model is a pre-training technique for NLP. It consists in masking some words in a sentence and then train a model to predict the masked words.}
}

\newacronym[description={\glslink{bertg}{Bidirectional Encoder Representations from Transformers}}]
{bert}{BERT}{Bidirectional Encoder Representations from Transformers}
\newglossaryentry{bertg}
{
    name=\glslink{bert}{BERT},
    text=Bidirectional Encoder Representations from Transformers,
    sort= bert,
    description={BERT is a method of pre-training language representations, which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
}

\newacronym[description={\glslink{nlig}{Natural Language Inference}}]
{nli}{NLI}{Natural Language Inference}
\newglossaryentry{nlig}
{
    name=\glslink{nli}{NLI},
    text=Natural Language Inference,
    sort= nli,
    description={Natural Language Inference (NLI) is a text classification task, where given a premise sentence and a hypothesis sentence, the model must predict the relationship between them. The relationship can be entailment, contradiction, or neutral.}
}

\newacronym[description={\glslink{seq2seqg}{Sequence to Sequence}}]
{seq2seq}{seq2seq}{Sequence to Sequence}
\newglossaryentry{seq2seqg}
{
    name=\glslink{seq2seq}{Seq2seq},
    text=Sequence to Sequence,
    sort=seq2seq,
    description={Seq2seq is a model that maps a sequence of symbols to another sequence of symbols.}
}

\newacronym[description={\glslink{dnng}{Deep Neural Network}}]
{dnn}{DNN}{Deep Neural Network}
\newglossaryentry{dnng}
{
    name=\glslink{dnn}{DNN},
    text=Deep Neural Network,
    sort=dnn,
    description={Deep Neural Network is a class of artificial neural networks that has multiple hidden layers between the input and output layers.}
}

\newacronym[description={\glslink{fsgmg}{Fast Sign Gradient Method}}]
{fsgm}{FSGM}{Fast Sign Gradient Method}
\newglossaryentry{fsgmg}
{
    name=\glslink{fsgm}{FSGM},
    text=Fast Sign Gradient Method,
    sort=fsgm,
    description={Fast Sign Gradient Method is a method to generate adversarial examples. It consists in adding a small perturbation to the input of a model. The perturbation is computed by taking the sign of the gradient of the loss function with respect to the input.}
}

\newacronym[description={\glslink{gang}{Generative Adversarial Network}}]
{gan}{GAN}{Generative Adversarial Network}
\newglossaryentry{gang}
{
    name=\glslink{gan}{GAN},
    text=Generative Adversarial Network,
    sort=gan,
    description={Generative Adversarial Networks are a class of machine learning systems invented by Ian Goodfellow in 2014. Two neural networks contest with each other in a game. Given a training set, this technique learns to generate new data with the same statistics as the training set.}
}


\newacronym[description={\glslink{tfidfg}{Term Frequency-Inverse Document Frequency}}]
{tfidf}{TF-IDF}{Term Frequency-Inverse Document Frequency}
\newglossaryentry{tfidfg}
{
    name=\glslink{tfidf}{TF-IDF},
    text=Term Frequency-Inverse Document Frequency,
    sort=tfidf,
    description={TF-IDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining.}
}

\newacronym[description={\glslink{gag}{Genetic Algorithm}}]
{ga}{GA}{Genetic Algorithm}
\newglossaryentry{gag}
{
    name=\glslink{ga}{GA},
    text=Genetic Algorithm,
    sort=ga,
    description={Genetic algorithms are search heuristics that mimic the process of natural selection. This algorithm repeatedly modifies a population of individual solutions. It does so by using operators such as selection, crossover, and mutation to create new generations of individuals.}
}

\newacronym[description={\glslink{psog}{Particle Swarm Optimization}}]
{pso}{PSO}{Particle Swarm Optimization}
\newglossaryentry{psog}
{
    name=\glslink{pso}{PSO},
    text=Particle Swarm Optimization,
    sort=pso,
    description={Particle Swarm Optimization is a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. It solves a problem by having a population of candidate solutions, here dubbed particles, and moving these particles around in the search-space according to simple mathematical formula over the particle's position and velocity.}
}

\newacronym[description={\glslink{rlg}{Reinforcement Learning}}]
{rl}{RL}{Reinforcement Learning}
\newglossaryentry{rlg}
{
    name=\glslink{rl}{RL},
    text=Reinforcement Learning,
    sort=rl,
    description={Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward.}
}

%**************************************************************
% Glossario
%**************************************************************
%\renewcommand{\glossaryname}{Glossario}




\newglossaryentry{word}
{
    name=\glslink{word}{Word},
    text=word,
    sort=word,
    description={Example of a term in the glossary}
}

\newglossaryentry{auto-regressive}
{
    name=\glslink{auto-regressive}{Auto-regressive},
    text=auto-regressive,
    sort=auto-regressive,
    description={A statistical  model is autoregressive if it predicts future values based on past values.}
}

\newglossaryentry{word embedding}
{
    name=\glslink{word embedding}{Word embedding},
    text=word embedding,
    sort=word embedding,
    description={Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.}
}

\newglossaryentry{lexicon}
{
    name=\glslink{lexicon}{Lexicon},
    text=lexicon,
    sort=lexicon,
    description={A lexicon is a collection of words along with associated information such as part of speech and sense definitions.}
}


\newglossaryentry{transformer}
{
    name=\glslink{transformer}{Transformer},
    text=transformer,
    sort=transformer,
    description={The Transformer is a model architecture for NLP. It is a neural network that uses attention mechanisms to learn contextual relations between words in a sentence.}
}

\newglossaryentry{bag-of-words}
{
    name=\glslink{bag-of-words}{Bag-of-words},
    text=bag-of-words,
    sort=bag-of-words,
    description={The bag-of-words model is a simplifying representation used in natural language processing and information retrieval. In this model, a text is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity.}
}

\newglossaryentry{language-model}
{
    name=\glslink{language-model}{Language model},
    text=language model,
    sort=language model,
    description={A language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability $P(w_1:w_2:...:w_m)$ to the whole sequence.}
}





