
\section{Solution}\label{sec:solution}
%**************************************************************
Researchers proposed special adversarial attacks in the text domain in order to maintain semantic consistency and syntactic correctness.
But those methods fail in generating high-quality adversarial examples since they frequently violate linguistic constraints.

This thesis concentrates on the adversarial attacks for text classification, in particular, the attacks based on sentiment analysis datasets, like IMDB \cite{maas-EtAl:2011:ACL-HLT2011} and Rotten Tomatoes \cite{pang-lee:2005a}.
Two state-of-the-art approaches, TextFooler \cite{journals/corr/abs-1907-11932} and BERT-based attack \cite{conf/emnlp/GargR20}, are compared to analyze weaknesses and strengths.

Then, their shortcomings are addressed by proposing a novel method, called SynBA, to generate adversarial examples for text data.
It is a word-level attack that generates adversarial examples by substituting words with candidates that have both a synonymy and contextual relationship with the original token.

The key contributions of this survey can be summarized as follows:
\begin{itemize}
    \item we introduce a simple but strong attack method, SynBA, to quickly generate high-profile utility-preserving adversarial examples that force the target models to make wrong predictions under the white-box setting;
    \item we propose a comprehensive automatic and human evaluation of adversarial attacks to evaluate the effectiveness, efficiency, and utility preserving properties of our system;
    \item we compare the adversarial examples generated by our method with TextFooler and BERT-based attack in terms of semantic similarity, semantic consistency, perturbation rate, success rate, perplexity and execution time.
\end{itemize}


% Our contributions. This survey concentrates on the adversarial
% attack and defense technology in the NLP field and provides a thorough and systematic review. 
%The key contributions of this survey
% can be summarized as follows:
%  We comprehensively and systematically summarize the textual
% adversarial attack and defense technology, elaborating on textual adversarial examples, adversarial attacks on texts, defenses
% against textual adversarial attacks, applications in various NLP
% tasks, and potential development directions in this domain.
%  We categorize current textual adversarial attacks according to
% the semantic granularity at the top level and further classify
% each class into several subclasses depending on the example
% generation strategy. To the best of our knowledge, we are the
% first to regard the example generation strategy as a classification criterion and propose this two-level classification for
% adversarial attacks.

%

% Briefly describe your methodology and/or theoretical approach
% Explain the aim of your research and what contribution it will make to the topic

% from TextFooler

% Our main contributions are summarized as follows:
% • We propose a simple but strong baseline, TEXTFOOLER, to quickly generate high-profile utility-preserving adversarial examples that force the target models to make wrong predictions under the black-box setting.
% • We evaluate TEXTFOOLER on three state-of-the-art deep learning models over five popular text classification tasks and two textual entailment tasks, and it achieved the state-of-the-art attack success rate and perturbation rate. Algorithm 1 Adversarial Attack by TEXTFOOLER
% • We propose a comprehensive four-way automatic and three-way human evaluation of language adversarial attacks to evaluate the effectiveness, efficiency, and utilitypreserving properties of our system.
% • We open-source the code, pre-trained target models, and test samples for the convenience of future benchmarking
